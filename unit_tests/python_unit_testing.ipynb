{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unit Testing in Python\n",
    "## For Data Science\n",
    "\n",
    "\n",
    "Sarah Braden\n",
    "\n",
    "Denver Data Science COP - 6/24/2019\n",
    "\n",
    "<img src=\"imgs/slalom.png\" align=left width=200 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Do you currently write unit tests for your code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unit Tests Are an Investment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"imgs/maybe-i-should.jpg\" align=center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unit Testing\n",
    "\n",
    "What, Why and Where?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Does your code do what it should?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Does your code continue to do what it should after you modify it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Must write functions if you are going to test them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Unit tests allow us to be more confident in our code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unit Testing\n",
    "Test-Driven Development can help *while* you're writing the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Test-Driven Development forces you to break down your code into smaller pieces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Smaller functions vs. one-big-script => code for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Breaking down your process into functions makes code more reusable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example - writing testable functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"imgs/flatfile.png\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"imgs/functions.png\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why Unit Tests for Data Science?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "* Data Science needs tests:  we deal with real life data and predictions - things get messy\n",
    "\n",
    "* Unit testing can give us confidence! \n",
    "  * Helps us make sure nothing went wrong while developing our model\n",
    "  * Prompts us to think what we want to achieve\n",
    "  * Forces us to think about edge cases where things can potentially go wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "$ pip install pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Basic Test\n",
    "\n",
    "In its simplest form, a **pytest** test is a function with test in the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_my_add.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_my_add.py\n",
    "\n",
    "def my_add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def test_my_add():\n",
    "    assert my_add(2, 3) == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Running the basic test\n",
    "\n",
    "Run the following command in the directory with the file: \n",
    "\n",
    "``py.test``\n",
    "\n",
    "The output would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform darwin -- Python 3.7.3, pytest-4.6.3, py-1.8.0, pluggy-0.12.0\r\n",
      "rootdir: /Users/sarah.braden/workspace/yakity-yak/unit_tests\r\n",
      "\u001b[1mcollecting ... \u001b[0m\u001b[1m\r",
      "collected 1 item                                                               \u001b[0m\r\n",
      "\r\n",
      "test_my_add.py \u001b[32m.\u001b[0m\u001b[36m                                                         [100%]\u001b[0m\r\n",
      "\r\n",
      "\u001b[32m\u001b[1m=========================== 1 passed in 0.01 seconds ===========================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!py.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Failed Test Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_my_add.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_my_add.py\n",
    "def my_add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def test_my_add():\n",
    "    assert my_add(2, 3) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.7.3, pytest-4.6.3, py-1.8.0, pluggy-0.12.0\n",
      "rootdir: /Users/sarah.braden/workspace/yakity-yak/unit_tests\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "test_my_add.py \u001b[31mF\u001b[0m\u001b[36m                                                         [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_________________________________ test_my_add __________________________________\u001b[0m\n",
      "\n",
      "\u001b[1m    def test_my_add():\u001b[0m\n",
      "\u001b[1m>       assert my_add(2, 3) == 6\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert 5 == 6\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 5 = my_add(2, 3)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_my_add.py\u001b[0m:6: AssertionError\n",
      "\u001b[31m\u001b[1m=========================== 1 failed in 0.06 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!py.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data science and unit testing can be tricky\n",
    "Let's discuss!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Two phases in our data science engagements: \n",
    "1. Exploratory\n",
    "2. Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Writing unit tests for all the features and algorithms stringently during the exploratory phase is not a realistic expectation for data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data science and unit testing can be tricky\n",
    "\n",
    "Why?\n",
    "\n",
    "During the Exploratory phase, we know a lot of code might not make into production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Science Testing Workflow\n",
    "\n",
    "1. Exploratory phase is over! Code is in a Jupyter Notebook\n",
    "2. It's time to Productionize the code!\n",
    "3. Where are your functions?\n",
    "     * Find repeated code/patterns. These chunks can be functions!\n",
    "     * Organize sections of code into functions by purpose or cells\n",
    "     * Don't make functions too big/long... it makes writing tests harder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Science Testing Workflow\n",
    "\n",
    "4. As you create your functions, write tests\n",
    "5. Separate your functions and tests into separate .py files\n",
    "6. Import the functions into the Jupyter Notebook instead of having them live in the Jupyter Notebook\n",
    "7. Run the tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What functionality would you unit test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's be Real: Unit Testing is Hard Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"imgs/one-does-not-simply-write-unit-tests.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"imgs/orly_unit_test.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Testing Types\n",
    "\n",
    "* **unit testing** - test functionality of individual procedures\n",
    "* **integration testing** - test how parts work together (interfaces)\n",
    "* **system testing** - testing the whole system at a high level (black box, functional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Testing in Python\n",
    "\n",
    "* [unittest](https://docs.python.org/2/library/unittest.html) (built-in) - assertion based\n",
    "* [doctest](https://docs.python.org/2/library/doctest.html) (built-in) - example based, integrated with docstrings\n",
    "* [nose](https://nose.readthedocs.org/en/latest/) - assertion based tests with framework and plugins\n",
    "* [pytest](http://pytest.org/latest/) - framework that supports all of the above and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Other Tools for Testing in Python\n",
    "* [tox](https://pypi.org/project/tox/) - virtualenv management for testing on different environments\n",
    "* [mock](https://docs.python.org/3/library/unittest.mock.html) (built-in) - create fake objects for unit tests\n",
    "- [moto](https://github.com/spulec/moto) - mocks AWS services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Where to Start?\n",
    "\n",
    "* pytest\n",
    "* mock\n",
    "* moto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pytest Test Discovery\n",
    "\n",
    "How does `pytest` find its tests?\n",
    "\n",
    "Tests will be found automatically if `test` is in the filename.\n",
    "\n",
    "Note: don't use function names with `test` unless it is a unit test!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pytest Test Discovery\n",
    "\n",
    "More details:\n",
    "\n",
    "* Test collection starts from the initial command line\n",
    "* Recursive into directories\n",
    "* `test_*.py` or `*_test.py` files, imported by their package name.\n",
    "* Classes prefixed with `Test`\n",
    "* Functions or methods prefixed with `test_`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_my_add.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_my_add.py\n",
    "\n",
    "def my_add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def test_my_add():\n",
    "    assert my_add(2, 3) == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Explaining the Basic Example\n",
    "\n",
    "* Basic example file was `test_my_add.py`\n",
    "* Executed by running: `py.test`\n",
    "* Execute by running `py.test my_add.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pytest, Doctest, and Unittest (oh my!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pytest and Doctest\n",
    "\n",
    "* By default, `pytest` only runs doctests in `*.txt` files\n",
    "* Add more with `--doctest-glob='*.rst'`\n",
    "* Run doctests in module docstrings with: `py.test --doctest-modules`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Two tests: a doctest and assertion based unit test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_my_add2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_my_add2.py\n",
    "\n",
    "def my_add(a, b):\n",
    "    \"\"\" Sample doctest\n",
    "    >>> my_add(3, 4)\n",
    "    7\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def test_my_add():\n",
    "    assert my_add(2, 3) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform darwin -- Python 3.7.3, pytest-4.6.3, py-1.8.0, pluggy-0.12.0\r\n",
      "rootdir: /Users/sarah.braden/workspace/yakity-yak/unit_tests\r\n",
      "\u001b[1mcollecting ... \u001b[0m\u001b[1m\r",
      "collected 1 item                                                               \u001b[0m\r\n",
      "\r\n",
      "test_my_add2.py \u001b[32m.\u001b[0m\u001b[36m                                                        [100%]\u001b[0m\r\n",
      "\r\n",
      "\u001b[32m\u001b[1m=========================== 1 passed in 0.03 seconds ===========================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!py.test test_my_add2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "only one test ran!?!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform darwin -- Python 3.7.3, pytest-4.6.3, py-1.8.0, pluggy-0.12.0\r\n",
      "rootdir: /Users/sarah.braden/workspace/yakity-yak/unit_tests\r\n",
      "\u001b[1mcollecting ... \u001b[0m\u001b[1m\r",
      "collected 2 items                                                              \u001b[0m\r\n",
      "\r\n",
      "test_my_add2.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                                       [100%]\u001b[0m\r\n",
      "\r\n",
      "\u001b[32m\u001b[1m=========================== 2 passed in 0.03 seconds ===========================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!py.test test_my_add2.py --doctest-modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "much better ... two run with **--doctest-modules** argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pytest and Python unittest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_my_add3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_my_add3.py\n",
    "import unittest\n",
    "\n",
    "def my_add(a,b):\n",
    "    return a + b\n",
    "\n",
    "class TestMyAdd(unittest.TestCase):\n",
    "    def test_add1(self):\n",
    "        assert my_add(3,4), 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.7.3, pytest-4.6.3, py-1.8.0, pluggy-0.12.0\n",
      "rootdir: /Users/sarah.braden/workspace/yakity-yak/unit_tests\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "test_my_add3.py \u001b[32m.\u001b[0m\u001b[36m                                                        [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 1 passed in 0.03 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!py.test test_my_add3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "runs as you would expect, without modification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reflection\n",
    "\n",
    "Just to be clear ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* use of **doctest** and **unittest** are optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* tests can be implemented as shown in the base example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* mix and match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Split your tests out into a separate file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "* Bonus organization points: put tests into a `test/` subdirectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mock and Mocking\n",
    "\n",
    "### Problem\n",
    "* Testing your code for ingesting data from an API\n",
    "* Make sure the code accurately parses/processes the json object the API returns\n",
    "* You don't actually want to call the API every time you run your unit tests (too much overhead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mock and Mocking\n",
    "\n",
    "### Solution\n",
    "\n",
    "Mock the json object returned by the API!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@pytest.fixture\n",
    "def english_response():\n",
    "    return Mock(\n",
    "        recording=Mock(id=374389),\n",
    "        question=Mock(locale='en-US', active=True),\n",
    "    )\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def spanish_response():\n",
    "    return Mock(\n",
    "        recording=Mock(id=864343),\n",
    "        question=Mock(locale='es-AR', active=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def test_choose_transcriber_model(english_response, spanish_response):\n",
    "    assert uhura.choose_transcriber_model(english_response.question.locale) == TRANSCRIBER_GOOGLE_ENHANCED\n",
    "    assert uhura.choose_transcriber_model(spanish_response.question.locale) == TRANSCRIBER_GOOGLE_DEFAULT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Side Note\n",
    "### What's a fixture?\n",
    "\n",
    "Fixtures are functions, which will run before each test function to which it is applied.\n",
    "\n",
    "Fixtures are used to \"feed\" something to the tests: objects, URLs to test, any kind of input data, whatever.\n",
    "\n",
    "Instead of running the same code for every test, we can attach fixture function to the tests and it will run and return the data to the test before executing each test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from mock import Mock, MagicMock\n",
    "import pytest\n",
    "\n",
    "from transcription.matching.test.scoring import uhura\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def choices():\n",
    "    return [\n",
    "        MagicMock(value=\"THE RAIN IN SPAIN\", correct=True),\n",
    "        MagicMock(value=\"FALLS MAINLY ON THE PLAIN\", correct=False),\n",
    "        MagicMock(value=\"MAKE IT SO NUMBER ONE\", correct=False),\n",
    "        MagicMock(value=\"YOU WILL NEVER FIND A MORE WRETCHED HIVE OF SCUM AND VILLAINY\", correct=False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "# Scenario: Choice matching\n",
    "###########################\n",
    "# Case 1:\n",
    "# Given a list of choices\n",
    "# When called with a phrase that matches choice 1\n",
    "# Then it returns choice 1\n",
    "def test_matching_good_choice(choices):\n",
    "    assert uhura.match_best_choice(\"The rain in spain\", choices, 'en-US') == choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Case 2:\n",
    "# Given a list of choices\n",
    "# When called with a phrase that matches no choices\n",
    "# Then it returns None\n",
    "def test_matching_no_choice(choices):\n",
    "    assert uhura.match_best_choice(\"Banded bulbous snarfblat\", choices, 'en-US') is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Moto for testing Boto\n",
    "Moto is a library that allows your tests to easily mock out AWS Services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "class MyModel(object):\n",
    "    def __init__(self, name, value):\n",
    "        self.name = name\n",
    "        self.value = value\n",
    "\n",
    "    def save(self):\n",
    "        s3 = boto3.client('s3', region_name='us-east-1')\n",
    "        s3.put_object(Bucket='mybucket', Key=self.name, Body=self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from moto import mock_s3\n",
    "from mymodule import MyModel\n",
    "\n",
    "\n",
    "@mock_s3\n",
    "def test_my_model_save():\n",
    "    conn = boto3.resource('s3', region_name='us-east-1')\n",
    "    conn.create_bucket(Bucket='mybucket') # create the 'virtual' Moto bucket\n",
    "    model_instance = MyModel('slalom', 'is awesome')\n",
    "    model_instance.save()\n",
    "    body = conn.Object('mybucket', 'slalom').get()['Body'].read().decode(\"utf-8\")\n",
    "    assert body == 'is awesome'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Read more\n",
    "* [Test-Driven Development for Data Science](http://engineering.pivotal.io/post/test-driven-development-for-data-science/)\n",
    "* [PySpark Coding Practices: Lessons Learned](https://engineeringblog.yelp.com/2018/05/pyspark-coding-practices-lessons-learned.html)\n",
    "* [Beyond Data Science - Unit testing](https://medium.com/@MohammedS/beyond-data-science-unit-testing-bb537af38426)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank You\n",
    "\n",
    "Sarah Braden - Twitter: @ifmoonwascookie\n",
    "\n",
    "Slides made with Jupyter Notebook and [RevealJS](https://revealjs.com)\n",
    "\n",
    "Slides available on [github](https://github.com/sbraden/yakity-yak/tree/master/unit_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What's that @ thing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A decorator is any callable Python object that is used to modify a function, method or class definition. \n",
    "\n",
    "* A decorator passes the original object being defined and returns a modified object, which is then bound to the name in the definition. \n",
    "\n",
    "* The decorator syntax is pure syntactic sugar, using @ as the keyword\n",
    "\n",
    "[Example taken from wikipedia](https://en.wikipedia.org/wiki/Python_syntax_and_semantics#Decorators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def viking_chorus(myfunc):\n",
    "    \"\"\"viking_chorus causes menu_item to be run 8 times.\"\"\"\n",
    "    def inner_func(*args, **kwargs):\n",
    "        for i in range(8):\n",
    "            myfunc(*args, **kwargs)\n",
    "    return inner_func\n",
    "\n",
    "\n",
    "@viking_chorus\n",
    "def menu_item():\n",
    "    print(\"spam\")\n",
    "\n",
    "# is equivalent to\n",
    "\n",
    "def menu_item():\n",
    "    print(\"spam\")\n",
    "menu_item = viking_chorus(menu_item)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
